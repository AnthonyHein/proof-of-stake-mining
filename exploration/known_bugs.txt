- If the exploration depth is x. Then for states with sequence length x, the explorer will not
bound this state with any ActionBound. It will only use LemmaLowerBound or LemmaUpperBound. This
is because taking an action and looking at subsequent states would exceed the exploration depth.

- Cannot use "promised" actions (like selfish mining) as lower bounds.

- state_utils.occurs_after_state() only promises to work correctly on states where the attacker
has not yet published anything. This is because it is very difficult to know _when_ blocks in the
longest path were added to the longest path and so it is difficult to know if a state occurs after
another in the general case.

- At the exploration depth, the explorer will not look at the action "Wait" since the subsequent
states exceed the exploration depth. In turn, the resulting bounds are inaccurate since the loosest
upper bound is usually due to waiting. To fix this, at the exploration depth the explorer does not
try out _any_ actions.

- Bounds like (A) are incomparable. I am getting a result that waiting yields a larger bound than
Lemma G.8 for a strength of alpha <= 0.3176 though I cannot explain this result and it is a lot
to chase down.

- This code does not terminate for some expressions when trying to compare bounds:

    domain = sp.Interval(settings["alpha_pos_lower_bound"], settings["alpha_pos_upper_bound"])
    # Comparison.
    try:
        soln = sp.solveset(expr_a <= expr_b, alpha, domain)
    except:
        soln = sp.Interval(settings["alpha_pos_lower_bound"], (settings["alpha_pos_lower_bound"] + settings["alpha_pos_upper_bound"]) / 2)

    if soln == domain:
        return True

    elif soln == sp.S.EmptySet:
        return False

    else:

- The code for commitments in `state_utils.py` seems rather fragile. Although not immediately obvious,
there is probably a better way to write it.

- Not sure how to define deficits and runs other than using the code found in `get_deficits_and_runs()`.
As the comment to this function suggests, this should be revisited.

- If I were to rewrite this codebase, I would make several things to be their own modules, like bounds
and commitments. Currently, they are typed dictionaries because I initially didn't see the point of
making them their own class since they didn't have functions/methods that acted upon them but probably
would be a cleaner solution nonetheless.

- As far as I can tell, fine tuning in the explorer doesn't actually update any states. I don't think
the function is _wrong_, but rather that there are just no states that benefit from a second pass. The
root cause of this may be the fact that we aren't considering lower bounds that may come from state
capitulations. For example, any state that ends in A, H where the A may not be published at the state
may capitulate to B_{1,1} for a larger lower bound than the lower bound of 0 which would inevitably
be used since there are no immediate actions or commitments.

- In `state_details.py` may want to further divide `lemma_bounds` into LemmaLowerBound dictionaries and
LemmaUpperBound dictionaries.

- There are actually even smarter applications of Lemma G.8 if the suffix of the state is a known state.
e.g. A, 2H, A, 2H, 2A

- Try to cut out actions that cannot be optimal (or at least use color to mark).

- Two modifications to Lemma G.8
* Modification 1: In recursive part of G.8 look at previously created tables.
* Modification 2: Implement a smarter search for G.8 partitions. In particular, look for states like
  (A,xH,2A) and (A,xH,A,H,A).

- Make Sphinx documentation.

- Double check definitions of elevated, patient, and non-checkpoint finality. In particular, I think
the min Q = v + 1 might be wrong.